(window.webpackJsonp=window.webpackJsonp||[]).push([[42],{440:function(v,e,_){"use strict";_.r(e);var t=_(45),n=Object(t.a)({},(function(){var v=this,e=v.$createElement,_=v._self._c||e;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("h1",{attrs:{id:"爬虫"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#爬虫"}},[v._v("#")]),v._v(" 爬虫")]),v._v(" "),_("p",[v._v("顾名思义就是对网站的内容进行爬取，大致流程如下："),_("br"),v._v("\n1 发送请求"),_("br"),v._v("\n2 获取数据"),_("br"),v._v("\n3 解析数据")]),v._v(" "),_("p",[v._v("现在很多网站都做了反爬虫处理，那么爬取的时候就需要做对应的处理, 比如:"),_("br"),v._v("\n1 客户端对设备、请求 "),_("code",[v._v("header")]),v._v(" 进行检测（解：更改请求设备参数、伪造 "),_("code",[v._v("header")]),v._v(" ）"),_("br"),v._v("\n2 对进去 ip 进行限制（解：使用 ip 池、代理 ip）"),_("br"),v._v("\n3 前端 JS 混淆加密md5、RSA等（解：分析加密代码进行解密）")]),v._v(" "),_("blockquote",[_("p",[v._v("不同的反爬虫手段理论上都有破解的办法，只是增加了爬取的成本，拦截住了一部分爬取")])]),v._v(" "),_("p",[_("code",[v._v("python")]),v._v(" 、"),_("code",[v._v("java")]),v._v("、"),_("code",[v._v("node")]),v._v(" 都可以用来写爬虫，"),_("code",[v._v("python")]),v._v(" 应该是使用人数最多的了，生态应该也比较健全，因为个人熟悉 "),_("code",[v._v("javascript")]),v._v(" 就首选 "),_("code",[v._v("node")]),v._v("。\n针对爬取对象情况不一样，可能就需要选取不一样的方案了。")])])}),[],!1,null,null,null);e.default=n.exports}}]);