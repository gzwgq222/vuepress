# 爬虫
顾名思义就是对网站的内容进行爬取，大致流程如下：  
1 发送请求  
2 获取数据  
3 解析数据  

现在很多网站都做了反爬虫处理，那么爬取的时候就需要做对应的处理, 比如:  
1 客户端对设备、请求 `header` 进行检测（解：更改请求设备参数、伪造 `header` ）  
2 对进去 ip 进行限制（解：使用 ip 池、代理 ip）   
3 前端 JS 混淆加密md5、RSA等（解：分析加密代码进行解密）    
> 不同的反爬虫手段理论上都有破解的办法，只是增加了爬取的成本，拦截住了一部分爬取

`python` 、`java`、`node` 都可以用来写爬虫，`python` 应该是使用人数最多的了，生态应该也比较健全，因为个人熟悉 `javascript` 就首选 `node`。
针对爬取对象情况不一样，可能就需要选取不一样的方案了。